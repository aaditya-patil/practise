{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "U-BiEr9Jy-Mv"
      },
      "outputs": [],
      "source": [
        "\n",
        "\n",
        "\n",
        "# Implementing feedforward neural networks with Keras and TensorFlow\n",
        "# import the necessary packages\n",
        "from sklearn.preprocessing import LabelBinarizer\n",
        "from sklearn.metrics import classification_report\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.datasets import mnist\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "# The LabelBinarizer will be used to one-hot encode our integer labels as vector labels. \n",
        "# One-hot encoding transforms categorical labels from a single integer to a vector\n",
        "# The classification_report function will give us a nicely formatted report displaying the total accuracy of our model, \n",
        "# along with a breakdown on the classification accuracy for each digit.\n",
        "# import the necessary packages to create a simple feedforward neural network with Keras. \n",
        "# The Sequential class indicates that our network will be feedforward and layers will be added to the class sequentially, one on top of the other. \n",
        "# The Dense class on Line 5 is the implementation of our fully connected layers. \n",
        "# For our network to actually learn, we need to apply SGD (Line 6) to optimize the parameters of the network. \n",
        "# Finally, to gain access to full MNIST dataset, we need to import the mnist helper function on Line 7"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# construct the argument parse and parse the arguments\n",
        "#ap = argparse.ArgumentParser()\n",
        "#ap.add_argument(\"-o\", \"--output\", required=True,\n",
        "\t#help=\"path to the output loss/accuracy plot\")\n",
        "#args = vars(ap.parse_args())\n",
        "\n",
        "# We only need a single switch here, --output, which is the path to where our figure \n",
        "# plotting the loss and accuracy over time will be saved to disk."
      ],
      "metadata": {
        "id": "XCGhZAG0_bUb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# grab the MNIST dataset (if this is your first time using this\n",
        "# dataset then the 11MB download may take a minute)\n",
        "\n",
        "print(\"[INFO] accessing MNIST...\")\n",
        "((trainX, trainY), (testX, testY)) = mnist.load_data()\n",
        "\n",
        "# each image in the MNIST dataset is represented as a 28x28x1\n",
        "# image, but in order to apply a standard neural network we must\n",
        "# first \"flatten\" the image to be simple list of 28x28=784 pixels\n",
        "\n",
        "trainX = trainX.reshape((trainX.shape[0], 28 * 28 * 1))\n",
        "testX = testX.reshape((testX.shape[0], 28 * 28 * 1))\n",
        "\n",
        "#perform data normalization on Lines 31 and 32 by scaling the pixel intensities to the range [0, 1].\n",
        "# scale data to the range of [0, 1]\n",
        "\n",
        "trainX = trainX.astype(\"float32\") / 255.0\n",
        "testX = testX.astype(\"float32\") / 255.0"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xKEidJBo_tiN",
        "outputId": "a8fe99ad-d45a-403b-c0d7-7ff980eb2288"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[INFO] accessing MNIST...\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
            "11493376/11490434 [==============================] - 0s 0us/step\n",
            "11501568/11490434 [==============================] - 0s 0us/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# convert the labels from integers to vectors\n",
        "lb = LabelBinarizer()\n",
        "trainY = lb.fit_transform(trainY)\n",
        "testY = lb.transform(testY)\n",
        "\n",
        "# Each data point in the MNIST dataset has an integer label in the range [0, 9], one for each of the possible ten digits in the MNIST dataset.\n",
        "# A label with a value of 0 indicates that the corresponding image contains a zero digit. Similarly, a label with a value of 8 indicates \n",
        "# that the corresponding image contains the number eight."
      ],
      "metadata": {
        "id": "3_p3xZg3ANuG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# However, we first need to transform these integer labels into vector labels, \n",
        "#where the index in the vector for label is set to 1 and 0 otherwise (this process is called one-hot encoding)."
      ],
      "metadata": {
        "id": "y9b3mNecAdmx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "one-hot encoding representations for each digit, 0−9, in the listing below:\n",
        "0: [1, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
        "1: [0, 1, 0, 0, 0, 0, 0, 0, 0, 0]\n",
        "2: [0, 0, 1, 0, 0, 0, 0, 0, 0, 0]\n",
        "3: [0, 0, 0, 1, 0, 0, 0, 0, 0, 0]\n",
        "4: [0, 0, 0, 0, 1, 0, 0, 0, 0, 0]\n",
        "5: [0, 0, 0, 0, 0, 1, 0, 0, 0, 0]\n",
        "6: [0, 0, 0, 0, 0, 0, 1, 0, 0, 0]\n",
        "7: [0, 0, 0, 0, 0, 0, 0, 1, 0, 0]\n",
        "8: [0, 0, 0, 0, 0, 0, 0, 0, 1, 0]\n",
        "9: [0, 0, 0, 0, 0, 0, 0, 0, 0, 1]"
      ],
      "metadata": {
        "id": "pSCXIJgVG69I"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "As you can see, our network is a feedforward architecture, instantiated by the Sequential class on Line 40 — \n",
        "this architecture implies that the layers will be stacked on top of each other with the output of the previous layer feeding into the next.\n",
        "\n",
        "Line 41 defines the first fully connected layer in the network. The input_shape is set to 784, \n",
        "the dimensionality of each MNIST data points. We then learn 256 weights in this layer and apply the sigmoid activation function. \n",
        "The next layer (Line 42) learns 128 weights. Finally, Line 43 applies another fully connected layer, \n",
        "this time only learning 10 weights, corresponding to the ten (0-9) output classes. Instead of a sigmoid activation,\n",
        "we’ll use a softmax activation to obtain normalized class probabilities for each prediction."
      ],
      "metadata": {
        "id": "XMmvu6V-HLdK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# define the 784-256-128-10 architecture using Keras\n",
        "model = Sequential()\n",
        "model.add(Dense(256, input_shape=(784,), activation=\"relu\"))\n",
        "model.add(Dense(128, activation=\"relu\"))\n",
        "model.add(Dense(64, activation=\"relu\"))\n",
        "model.add(Dense(10, activation=\"softmax\"))\n",
        "\n",
        "# train the model using Adam\n",
        "print(\"[INFO] training network...\")\n",
        "Adm = Adam(0.01)\n",
        "model.compile(loss=\"categorical_crossentropy\", optimizer=Adm, metrics=[\"accuracy\"])\n",
        "H = model.fit(trainX, trainY, validation_data=(testX, testY), epochs=100, batch_size=128)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ByJJesflFobX",
        "outputId": "fd073b0e-6893-47b2-b1ee-d783e5b166ac"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[INFO] training network...\n",
            "Epoch 1/100\n",
            "469/469 [==============================] - 4s 8ms/step - loss: 0.2585 - accuracy: 0.9212 - val_loss: 0.1412 - val_accuracy: 0.9577\n",
            "Epoch 2/100\n",
            "469/469 [==============================] - 3s 7ms/step - loss: 0.1306 - accuracy: 0.9624 - val_loss: 0.1209 - val_accuracy: 0.9654\n",
            "Epoch 3/100\n",
            "469/469 [==============================] - 3s 7ms/step - loss: 0.1021 - accuracy: 0.9707 - val_loss: 0.1383 - val_accuracy: 0.9624\n",
            "Epoch 4/100\n",
            "469/469 [==============================] - 4s 9ms/step - loss: 0.0916 - accuracy: 0.9740 - val_loss: 0.1151 - val_accuracy: 0.9706\n",
            "Epoch 5/100\n",
            "469/469 [==============================] - 4s 8ms/step - loss: 0.0858 - accuracy: 0.9747 - val_loss: 0.1184 - val_accuracy: 0.9681\n",
            "Epoch 6/100\n",
            "469/469 [==============================] - 3s 7ms/step - loss: 0.0805 - accuracy: 0.9781 - val_loss: 0.1316 - val_accuracy: 0.9672\n",
            "Epoch 7/100\n",
            "469/469 [==============================] - 3s 7ms/step - loss: 0.0698 - accuracy: 0.9805 - val_loss: 0.1598 - val_accuracy: 0.9657\n",
            "Epoch 8/100\n",
            "469/469 [==============================] - 3s 7ms/step - loss: 0.0747 - accuracy: 0.9805 - val_loss: 0.1359 - val_accuracy: 0.9703\n",
            "Epoch 9/100\n",
            "469/469 [==============================] - 3s 7ms/step - loss: 0.0670 - accuracy: 0.9818 - val_loss: 0.1306 - val_accuracy: 0.9740\n",
            "Epoch 10/100\n",
            "469/469 [==============================] - 3s 7ms/step - loss: 0.0620 - accuracy: 0.9834 - val_loss: 0.1361 - val_accuracy: 0.9711\n",
            "Epoch 11/100\n",
            "469/469 [==============================] - 3s 7ms/step - loss: 0.0625 - accuracy: 0.9834 - val_loss: 0.1227 - val_accuracy: 0.9735\n",
            "Epoch 12/100\n",
            "469/469 [==============================] - 3s 7ms/step - loss: 0.0600 - accuracy: 0.9846 - val_loss: 0.1316 - val_accuracy: 0.9712\n",
            "Epoch 13/100\n",
            "469/469 [==============================] - 3s 7ms/step - loss: 0.0572 - accuracy: 0.9851 - val_loss: 0.1406 - val_accuracy: 0.9707\n",
            "Epoch 14/100\n",
            "469/469 [==============================] - 3s 7ms/step - loss: 0.0506 - accuracy: 0.9864 - val_loss: 0.1293 - val_accuracy: 0.9750\n",
            "Epoch 15/100\n",
            "469/469 [==============================] - 3s 7ms/step - loss: 0.0612 - accuracy: 0.9858 - val_loss: 0.2036 - val_accuracy: 0.9709\n",
            "Epoch 16/100\n",
            "469/469 [==============================] - 3s 7ms/step - loss: 0.0577 - accuracy: 0.9863 - val_loss: 0.1633 - val_accuracy: 0.9758\n",
            "Epoch 17/100\n",
            "469/469 [==============================] - 3s 7ms/step - loss: 0.0473 - accuracy: 0.9886 - val_loss: 0.1710 - val_accuracy: 0.9723\n",
            "Epoch 18/100\n",
            "469/469 [==============================] - 4s 9ms/step - loss: 0.0438 - accuracy: 0.9896 - val_loss: 0.1650 - val_accuracy: 0.9729\n",
            "Epoch 19/100\n",
            "469/469 [==============================] - 3s 7ms/step - loss: 0.0495 - accuracy: 0.9884 - val_loss: 0.1495 - val_accuracy: 0.9757\n",
            "Epoch 20/100\n",
            "469/469 [==============================] - 3s 7ms/step - loss: 0.0401 - accuracy: 0.9902 - val_loss: 0.1791 - val_accuracy: 0.9649\n",
            "Epoch 21/100\n",
            "469/469 [==============================] - 3s 7ms/step - loss: 0.0434 - accuracy: 0.9905 - val_loss: 0.1987 - val_accuracy: 0.9710\n",
            "Epoch 22/100\n",
            "469/469 [==============================] - 3s 7ms/step - loss: 0.0547 - accuracy: 0.9883 - val_loss: 0.1873 - val_accuracy: 0.9688\n",
            "Epoch 23/100\n",
            "469/469 [==============================] - 3s 7ms/step - loss: 0.0476 - accuracy: 0.9896 - val_loss: 0.1603 - val_accuracy: 0.9718\n",
            "Epoch 24/100\n",
            "469/469 [==============================] - 3s 7ms/step - loss: 0.0375 - accuracy: 0.9912 - val_loss: 0.2010 - val_accuracy: 0.9756\n",
            "Epoch 25/100\n",
            "469/469 [==============================] - 3s 7ms/step - loss: 0.0493 - accuracy: 0.9892 - val_loss: 0.1650 - val_accuracy: 0.9775\n",
            "Epoch 26/100\n",
            "469/469 [==============================] - 3s 7ms/step - loss: 0.0356 - accuracy: 0.9921 - val_loss: 0.1962 - val_accuracy: 0.9779\n",
            "Epoch 27/100\n",
            "469/469 [==============================] - 3s 7ms/step - loss: 0.0391 - accuracy: 0.9912 - val_loss: 0.1626 - val_accuracy: 0.9771\n",
            "Epoch 28/100\n",
            "469/469 [==============================] - 3s 7ms/step - loss: 0.0345 - accuracy: 0.9926 - val_loss: 0.2135 - val_accuracy: 0.9762\n",
            "Epoch 29/100\n",
            "469/469 [==============================] - 3s 7ms/step - loss: 0.0410 - accuracy: 0.9912 - val_loss: 0.1643 - val_accuracy: 0.9759\n",
            "Epoch 30/100\n",
            "469/469 [==============================] - 3s 7ms/step - loss: 0.0407 - accuracy: 0.9909 - val_loss: 0.2119 - val_accuracy: 0.9673\n",
            "Epoch 31/100\n",
            "469/469 [==============================] - 3s 7ms/step - loss: 0.0499 - accuracy: 0.9898 - val_loss: 0.2036 - val_accuracy: 0.9759\n",
            "Epoch 32/100\n",
            "469/469 [==============================] - 3s 7ms/step - loss: 0.0374 - accuracy: 0.9922 - val_loss: 0.1814 - val_accuracy: 0.9747\n",
            "Epoch 33/100\n",
            "469/469 [==============================] - 3s 7ms/step - loss: 0.0426 - accuracy: 0.9912 - val_loss: 0.2087 - val_accuracy: 0.9766\n",
            "Epoch 34/100\n",
            "469/469 [==============================] - 3s 7ms/step - loss: 0.0413 - accuracy: 0.9918 - val_loss: 0.2136 - val_accuracy: 0.9782\n",
            "Epoch 35/100\n",
            "469/469 [==============================] - 3s 7ms/step - loss: 0.0321 - accuracy: 0.9930 - val_loss: 0.1721 - val_accuracy: 0.9777\n",
            "Epoch 36/100\n",
            "469/469 [==============================] - 3s 7ms/step - loss: 0.0391 - accuracy: 0.9918 - val_loss: 0.2219 - val_accuracy: 0.9762\n",
            "Epoch 37/100\n",
            "469/469 [==============================] - 3s 7ms/step - loss: 0.0356 - accuracy: 0.9929 - val_loss: 0.2588 - val_accuracy: 0.9755\n",
            "Epoch 38/100\n",
            "469/469 [==============================] - 3s 7ms/step - loss: 0.0502 - accuracy: 0.9909 - val_loss: 0.2934 - val_accuracy: 0.9684\n",
            "Epoch 39/100\n",
            "469/469 [==============================] - 3s 7ms/step - loss: 0.0439 - accuracy: 0.9919 - val_loss: 0.1955 - val_accuracy: 0.9756\n",
            "Epoch 40/100\n",
            "469/469 [==============================] - 3s 7ms/step - loss: 0.0319 - accuracy: 0.9937 - val_loss: 0.2076 - val_accuracy: 0.9769\n",
            "Epoch 41/100\n",
            "469/469 [==============================] - 3s 7ms/step - loss: 0.0274 - accuracy: 0.9945 - val_loss: 0.2393 - val_accuracy: 0.9765\n",
            "Epoch 42/100\n",
            "469/469 [==============================] - 3s 7ms/step - loss: 0.0310 - accuracy: 0.9933 - val_loss: 0.2169 - val_accuracy: 0.9762\n",
            "Epoch 43/100\n",
            "469/469 [==============================] - 3s 7ms/step - loss: 0.0294 - accuracy: 0.9936 - val_loss: 0.3118 - val_accuracy: 0.9757\n",
            "Epoch 44/100\n",
            "469/469 [==============================] - 3s 7ms/step - loss: 0.0297 - accuracy: 0.9939 - val_loss: 0.2542 - val_accuracy: 0.9746\n",
            "Epoch 45/100\n",
            "469/469 [==============================] - 3s 7ms/step - loss: 0.0457 - accuracy: 0.9917 - val_loss: 0.3098 - val_accuracy: 0.9700\n",
            "Epoch 46/100\n",
            "469/469 [==============================] - 3s 7ms/step - loss: 0.0488 - accuracy: 0.9901 - val_loss: 0.2977 - val_accuracy: 0.9740\n",
            "Epoch 47/100\n",
            "469/469 [==============================] - 3s 7ms/step - loss: 0.0332 - accuracy: 0.9944 - val_loss: 0.2543 - val_accuracy: 0.9757\n",
            "Epoch 48/100\n",
            "469/469 [==============================] - 3s 7ms/step - loss: 0.0333 - accuracy: 0.9942 - val_loss: 0.2487 - val_accuracy: 0.9779\n",
            "Epoch 49/100\n",
            "469/469 [==============================] - 4s 9ms/step - loss: 0.0397 - accuracy: 0.9932 - val_loss: 0.2452 - val_accuracy: 0.9742\n",
            "Epoch 50/100\n",
            "469/469 [==============================] - 3s 7ms/step - loss: 0.0349 - accuracy: 0.9925 - val_loss: 0.2008 - val_accuracy: 0.9778\n",
            "Epoch 51/100\n",
            "469/469 [==============================] - 4s 9ms/step - loss: 0.0215 - accuracy: 0.9953 - val_loss: 0.3074 - val_accuracy: 0.9780\n",
            "Epoch 52/100\n",
            "469/469 [==============================] - 4s 8ms/step - loss: 0.0359 - accuracy: 0.9936 - val_loss: 0.3138 - val_accuracy: 0.9740\n",
            "Epoch 53/100\n",
            "469/469 [==============================] - 3s 7ms/step - loss: 0.0523 - accuracy: 0.9912 - val_loss: 0.3094 - val_accuracy: 0.9759\n",
            "Epoch 54/100\n",
            "469/469 [==============================] - 3s 7ms/step - loss: 0.0365 - accuracy: 0.9931 - val_loss: 0.2169 - val_accuracy: 0.9777\n",
            "Epoch 55/100\n",
            "469/469 [==============================] - 3s 7ms/step - loss: 0.0226 - accuracy: 0.9952 - val_loss: 0.2713 - val_accuracy: 0.9749\n",
            "Epoch 56/100\n",
            "469/469 [==============================] - 3s 7ms/step - loss: 0.0304 - accuracy: 0.9940 - val_loss: 0.2721 - val_accuracy: 0.9749\n",
            "Epoch 57/100\n",
            "469/469 [==============================] - 3s 7ms/step - loss: 0.0316 - accuracy: 0.9938 - val_loss: 0.2252 - val_accuracy: 0.9762\n",
            "Epoch 58/100\n",
            "469/469 [==============================] - 3s 7ms/step - loss: 0.0350 - accuracy: 0.9938 - val_loss: 0.2796 - val_accuracy: 0.9758\n",
            "Epoch 59/100\n",
            "469/469 [==============================] - 4s 8ms/step - loss: 0.0265 - accuracy: 0.9949 - val_loss: 0.2709 - val_accuracy: 0.9745\n",
            "Epoch 60/100\n",
            "469/469 [==============================] - 3s 7ms/step - loss: 0.0277 - accuracy: 0.9946 - val_loss: 0.2872 - val_accuracy: 0.9737\n",
            "Epoch 61/100\n",
            "469/469 [==============================] - 3s 7ms/step - loss: 0.0295 - accuracy: 0.9946 - val_loss: 0.3305 - val_accuracy: 0.9749\n",
            "Epoch 62/100\n",
            "469/469 [==============================] - 3s 7ms/step - loss: 0.0202 - accuracy: 0.9960 - val_loss: 0.3417 - val_accuracy: 0.9778\n",
            "Epoch 63/100\n",
            "469/469 [==============================] - 4s 8ms/step - loss: 0.0259 - accuracy: 0.9950 - val_loss: 0.3144 - val_accuracy: 0.9723\n",
            "Epoch 64/100\n",
            "469/469 [==============================] - 3s 7ms/step - loss: 0.0324 - accuracy: 0.9945 - val_loss: 0.3273 - val_accuracy: 0.9733\n",
            "Epoch 65/100\n",
            "469/469 [==============================] - 3s 7ms/step - loss: 0.0330 - accuracy: 0.9937 - val_loss: 0.2341 - val_accuracy: 0.9783\n",
            "Epoch 66/100\n",
            "469/469 [==============================] - 3s 7ms/step - loss: 0.0275 - accuracy: 0.9952 - val_loss: 0.3036 - val_accuracy: 0.9760\n",
            "Epoch 67/100\n",
            "469/469 [==============================] - 3s 7ms/step - loss: 0.0233 - accuracy: 0.9957 - val_loss: 0.3160 - val_accuracy: 0.9763\n",
            "Epoch 68/100\n",
            "469/469 [==============================] - 3s 7ms/step - loss: 0.0332 - accuracy: 0.9940 - val_loss: 0.2853 - val_accuracy: 0.9742\n",
            "Epoch 69/100\n",
            "469/469 [==============================] - 3s 7ms/step - loss: 0.0301 - accuracy: 0.9947 - val_loss: 0.3335 - val_accuracy: 0.9741\n",
            "Epoch 70/100\n",
            "469/469 [==============================] - 3s 7ms/step - loss: 0.0334 - accuracy: 0.9947 - val_loss: 0.3458 - val_accuracy: 0.9737\n",
            "Epoch 71/100\n",
            "469/469 [==============================] - 3s 7ms/step - loss: 0.0319 - accuracy: 0.9944 - val_loss: 0.2874 - val_accuracy: 0.9739\n",
            "Epoch 72/100\n",
            "469/469 [==============================] - 4s 8ms/step - loss: 0.0253 - accuracy: 0.9957 - val_loss: 0.2337 - val_accuracy: 0.9775\n",
            "Epoch 73/100\n",
            "469/469 [==============================] - 3s 7ms/step - loss: 0.0187 - accuracy: 0.9964 - val_loss: 0.3008 - val_accuracy: 0.9751\n",
            "Epoch 74/100\n",
            "469/469 [==============================] - 3s 7ms/step - loss: 0.0331 - accuracy: 0.9939 - val_loss: 0.3046 - val_accuracy: 0.9746\n",
            "Epoch 75/100\n",
            "469/469 [==============================] - 3s 7ms/step - loss: 0.0185 - accuracy: 0.9964 - val_loss: 0.3497 - val_accuracy: 0.9739\n",
            "Epoch 76/100\n",
            "469/469 [==============================] - 3s 7ms/step - loss: 0.0416 - accuracy: 0.9934 - val_loss: 0.2883 - val_accuracy: 0.9760\n",
            "Epoch 77/100\n",
            "469/469 [==============================] - 3s 7ms/step - loss: 0.0432 - accuracy: 0.9937 - val_loss: 0.3549 - val_accuracy: 0.9716\n",
            "Epoch 78/100\n",
            "469/469 [==============================] - 3s 7ms/step - loss: 0.0393 - accuracy: 0.9927 - val_loss: 0.3168 - val_accuracy: 0.9745\n",
            "Epoch 79/100\n",
            "469/469 [==============================] - 5s 10ms/step - loss: 0.0293 - accuracy: 0.9952 - val_loss: 0.3561 - val_accuracy: 0.9770\n",
            "Epoch 80/100\n",
            "469/469 [==============================] - 3s 7ms/step - loss: 0.0185 - accuracy: 0.9966 - val_loss: 0.3118 - val_accuracy: 0.9741\n",
            "Epoch 81/100\n",
            "469/469 [==============================] - 3s 7ms/step - loss: 0.0184 - accuracy: 0.9963 - val_loss: 0.2818 - val_accuracy: 0.9761\n",
            "Epoch 82/100\n",
            "469/469 [==============================] - 3s 7ms/step - loss: 0.0187 - accuracy: 0.9962 - val_loss: 0.4430 - val_accuracy: 0.9737\n",
            "Epoch 83/100\n",
            "469/469 [==============================] - 3s 7ms/step - loss: 0.0257 - accuracy: 0.9956 - val_loss: 0.3923 - val_accuracy: 0.9733\n",
            "Epoch 84/100\n",
            "469/469 [==============================] - 3s 7ms/step - loss: 0.0184 - accuracy: 0.9963 - val_loss: 0.3610 - val_accuracy: 0.9769\n",
            "Epoch 85/100\n",
            "469/469 [==============================] - 3s 7ms/step - loss: 0.0206 - accuracy: 0.9959 - val_loss: 0.3460 - val_accuracy: 0.9725\n",
            "Epoch 86/100\n",
            "469/469 [==============================] - 5s 12ms/step - loss: 0.0241 - accuracy: 0.9956 - val_loss: 0.4776 - val_accuracy: 0.9744\n",
            "Epoch 87/100\n",
            "469/469 [==============================] - 6s 13ms/step - loss: 0.0313 - accuracy: 0.9943 - val_loss: 0.4315 - val_accuracy: 0.9761\n",
            "Epoch 88/100\n",
            "469/469 [==============================] - 5s 11ms/step - loss: 0.0357 - accuracy: 0.9946 - val_loss: 0.3175 - val_accuracy: 0.9736\n",
            "Epoch 89/100\n",
            "469/469 [==============================] - 6s 12ms/step - loss: 0.0281 - accuracy: 0.9956 - val_loss: 0.3012 - val_accuracy: 0.9755\n",
            "Epoch 90/100\n",
            "469/469 [==============================] - 4s 9ms/step - loss: 0.0315 - accuracy: 0.9954 - val_loss: 0.4287 - val_accuracy: 0.9767\n",
            "Epoch 91/100\n",
            "469/469 [==============================] - 3s 7ms/step - loss: 0.0219 - accuracy: 0.9960 - val_loss: 0.3829 - val_accuracy: 0.9774\n",
            "Epoch 92/100\n",
            "469/469 [==============================] - 3s 7ms/step - loss: 0.0293 - accuracy: 0.9952 - val_loss: 0.3667 - val_accuracy: 0.9759\n",
            "Epoch 93/100\n",
            "469/469 [==============================] - 3s 7ms/step - loss: 0.0183 - accuracy: 0.9961 - val_loss: 0.4318 - val_accuracy: 0.9770\n",
            "Epoch 94/100\n",
            "469/469 [==============================] - 4s 8ms/step - loss: 0.0410 - accuracy: 0.9938 - val_loss: 0.3636 - val_accuracy: 0.9761\n",
            "Epoch 95/100\n",
            "469/469 [==============================] - 3s 7ms/step - loss: 0.0242 - accuracy: 0.9955 - val_loss: 0.4163 - val_accuracy: 0.9760\n",
            "Epoch 96/100\n",
            "469/469 [==============================] - 3s 7ms/step - loss: 0.0267 - accuracy: 0.9952 - val_loss: 0.6017 - val_accuracy: 0.9763\n",
            "Epoch 97/100\n",
            "469/469 [==============================] - 4s 8ms/step - loss: 0.0302 - accuracy: 0.9948 - val_loss: 0.3433 - val_accuracy: 0.9768\n",
            "Epoch 98/100\n",
            "469/469 [==============================] - 3s 7ms/step - loss: 0.0188 - accuracy: 0.9963 - val_loss: 0.4586 - val_accuracy: 0.9756\n",
            "Epoch 99/100\n",
            "469/469 [==============================] - 3s 7ms/step - loss: 0.0179 - accuracy: 0.9966 - val_loss: 0.4191 - val_accuracy: 0.9746\n",
            "Epoch 100/100\n",
            "469/469 [==============================] - 3s 7ms/step - loss: 0.0198 - accuracy: 0.9962 - val_loss: 0.4091 - val_accuracy: 0.9770\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "In Line 47, we initialize the SGD optimizer with a learning rate of 0.01 (which we may commonly write as 1e-2). \n",
        "We’ll use the category cross-entropy loss function as our loss metric (Lines 48 and 49). Using the cross-entropy\n",
        " loss function is also why we had to convert our integer labels to vector labels.\n",
        "\n",
        "A call to .fit of the model on Lines 50 and 51 kicks off the training of our neural network. \n",
        "We’ll supply the training data and training labels as the first two arguments to the method.*italicized text*"
      ],
      "metadata": {
        "id": "QWIYpr2EHNtn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# evaluate the network\n",
        "print(\"[INFO] evaluating network...\")\n",
        "predictions = model.predict(testX, batch_size=128)\n",
        "print(classification_report(testY.argmax(axis=1),\n",
        "\tpredictions.argmax(axis=1),\n",
        "\ttarget_names=[str(x) for x in lb.classes_]))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_2rhtL4KGAB4",
        "outputId": "5664688c-90ba-45cc-feaf-61ebd469a645"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[INFO] evaluating network...\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.94      0.98      0.96       980\n",
            "           1       0.97      0.98      0.97      1135\n",
            "           2       0.93      0.90      0.92      1032\n",
            "           3       0.91      0.91      0.91      1010\n",
            "           4       0.92      0.93      0.93       982\n",
            "           5       0.89      0.88      0.88       892\n",
            "           6       0.94      0.94      0.94       958\n",
            "           7       0.93      0.93      0.93      1028\n",
            "           8       0.90      0.89      0.89       974\n",
            "           9       0.92      0.90      0.91      1009\n",
            "\n",
            "    accuracy                           0.92     10000\n",
            "   macro avg       0.92      0.92      0.92     10000\n",
            "weighted avg       0.92      0.92      0.92     10000\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# plot the training loss and accuracy\n",
        "plt.style.use(\"ggplot\")\n",
        "plt.figure()\n",
        "plt.plot(np.arange(0, 100), H.history[\"loss\"], label=\"train_loss\")\n",
        "plt.plot(np.arange(0, 100), H.history[\"val_loss\"], label=\"val_loss\")\n",
        "plt.plot(np.arange(0, 100), H.history[\"accuracy\"], label=\"train_acc\")\n",
        "plt.plot(np.arange(0, 100), H.history[\"val_accuracy\"], label=\"val_acc\")\n",
        "plt.title(\"Training Loss and Accuracy\")\n",
        "plt.xlabel(\"Epoch #\")\n",
        "plt.ylabel(\"Loss/Accuracy\")\n",
        "plt.legend()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 482
        },
        "id": "Ku2GamqqGIns",
        "outputId": "ba49d484-dddb-45ea-cdbf-d4081e53299f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-8-f19faa8d29d1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mylabel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Loss/Accuracy\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlegend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msavefig\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"output\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'args' is not defined"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# To train our network of fully connected layers on MNIST, just execute the following command:\n",
        "\n",
        "$ python keras_mnist.py --output output/keras_mnist.png"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 130
        },
        "id": "PRcZEP6ZGQ5z",
        "outputId": "fbc2b643-fc90-47f4-96a8-6b29da62146d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "SyntaxError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-9-6af70ffafde5>\"\u001b[0;36m, line \u001b[0;32m3\u001b[0m\n\u001b[0;31m    $ python keras_mnist.py --output output/keras_mnist.png\u001b[0m\n\u001b[0m    ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
          ]
        }
      ]
    }
  ]
}